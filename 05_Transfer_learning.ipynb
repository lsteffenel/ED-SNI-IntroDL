{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "10-Transfer_learning.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ATTENTION\n",
        "\n",
        "Ce Notebook nécessite des ressources GPU. Pour cela, utilisez l'environnement Google Colab plutôt que Binder :\n",
        "\n",
        "[Lien vers Google Colab](https://colab.research.google.com/github/lsteffenel/M2Atmo_et_Climat/blob/main/10-Transfer_learning.ipynb)"
      ],
      "metadata": {
        "id": "JZciHVQirr3G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHWeT3yfgD5o"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evQL8FE_gD5p"
      },
      "source": [
        "Jusqu'à présent, nous avons entraîné des modèles précis sur de grands ensembles de données, et nous avons également téléchargé un modèle pré-entraîné que nous avons utilisé sans avoir besoin d'entraînement. Mais que se passe-t-il si nous ne trouvons pas de modèle pré-entraîné qui réponde exactement à vos besoins, et si nous ne disposons pas d'un ensemble de données suffisamment important pour entraîner un modèle à partir de zéro ? Dans ce cas, il existe une technique très utile appelée [apprentissage par transfert] (https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/).\n",
        "\n",
        "Avec l'apprentissage par transfert, nous prenons un modèle pré-entraîné et le réentraînons sur une tâche qui a un certain chevauchement avec la tâche d'entraînement d'origine. Une bonne analogie est celle d'un artiste compétent dans un domaine, comme la peinture, qui souhaite apprendre à s'exercer dans un autre domaine, comme le dessin au fusain. On peut imaginer que les compétences acquises en peignant seront très utiles pour apprendre à dessiner au fusain. \n",
        "\n",
        "Dans le domaine de l'apprentissage profond, supposons que nous disposions d'un modèle pré-entraîné très performant pour reconnaître différents types de voitures et que nous souhaitions entraîner un modèle à reconnaître des types de motocyclettes. Une grande partie des apprentissages du modèle de voiture serait probablement très utile, par exemple la capacité à reconnaître les phares et les roues. \n",
        "\n",
        "L'apprentissage par transfert est particulièrement efficace lorsque nous ne disposons pas d'un ensemble de données vaste et varié. Dans ce cas, un modèle formé à partir de zéro mémoriserait rapidement les données d'apprentissage, mais ne serait pas en mesure de se généraliser à de nouvelles données. Grâce à l'apprentissage par transfert, vous pouvez augmenter vos chances de former un modèle précis et robuste sur un petit ensemble de données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG7vpU4cgD5q"
      },
      "source": [
        "## Objectifs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ_NyExKgD5q"
      },
      "source": [
        "* Préparer un modèle pré-entraîné pour l'apprentissage par transfert\n",
        "* Effectuer l'apprentissage par transfert avec votre propre petit ensemble de données sur un modèle pré-entraîné\n",
        "* Ajustement du modèle pour une performance encore meilleure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZaldEDgHUY"
      },
      "source": [
        "!wget http://urca.lsteffenel.fr/IntroDL/data.tar.gz -O data.tar.gz\n",
        "!tar -xvzf data.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbttqHVZgD5r"
      },
      "source": [
        "## A Personalized Doggy Door"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWkL22_vgD5r"
      },
      "source": [
        "Dans notre dernier exercice, nous avons utilisé un modèle [ImageNet] (http://www.image-net.org/) pré-entraîné pour laisser entrer tous les chiens, mais exclure les autres animaux. Dans cet exercice, nous souhaitons créer une porte pour chien qui ne laisse entrer qu'un chien en particulier. Dans ce cas, nous allons créer une niche automatique pour un chien nommé Bo, premier chien des États-Unis entre 2009 et 2017. Les photos de Bo se trouvent dans le dossier `data/presidential_doggy_door`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3MZl3HagD5s"
      },
      "source": [
        "Le problème est que le modèle pré-entraîné n'a pas été entraîné à reconnaître ce chien spécifique et que nous ne disposons que de 30 images de Bo. Si nous essayons de former un modèle à partir de zéro en utilisant ces 30 photos, nous serons confrontés à un surajustement et à une mauvaise généralisation. En revanche, si nous partons d'un modèle pré-entraîné capable de détecter les chiens, nous pouvons tirer parti de cet apprentissage pour acquérir une compréhension généralisée de Bo en utilisant notre petit ensemble de données. Nous pouvons utiliser l'apprentissage par transfert pour relever ce défi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "undnRJ--gD5t"
      },
      "source": [
        "## Téléchargement du modèle pré-entraîné"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR9Uvq21gD5u"
      },
      "source": [
        "Les [modèles pré-entraînés ImageNet](https://keras.io/api/applications/vgg/#vgg16-function) sont souvent de bons choix pour l'apprentissage par transfert de la vision par ordinateur, car ils ont appris à classer différents types d'images. Ce faisant, ils ont appris à détecter de nombreux types de [caractéristiques] (https://developers.google.com/machine-learning/glossary#) susceptibles d'être utiles pour la reconnaissance d'images. Comme les modèles ImageNet ont appris à détecter les animaux, y compris les chiens, ils sont particulièrement adaptés à cette tâche d'apprentissage par transfert qu'est la détection de Bo.\n",
        "\n",
        "Commençons par télécharger le modèle pré-entraîné. Là encore, ce modèle est disponible directement à partir de la bibliothèque Keras. Lors du téléchargement, il y aura une différence importante. La dernière couche d'un modèle ImageNet est une [couche dense] (https://developers.google.com/machine-learning/glossary#dense-layer) de 1000 unités, représentant les 1000 classes possibles de l'ensemble de données. Dans notre cas, nous voulons que la classification soit différente : **est-ce que c'est Bo ou pas ?** \n",
        "\n",
        "Parce que nous voulons que la classification soit différente, nous allons supprimer la dernière couche du modèle. Nous pouvons le faire en réglant le drapeau `include_top=False` lors du téléchargement du modèle. Après avoir supprimé cette couche supérieure, nous pouvons ajouter de nouvelles couches qui produiront le type de classification que nous voulons :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3H3nyyRgD5v"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktfSq4dDgD5x"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4hW0VvigD5x"
      },
      "source": [
        "## Geler le modèle de base\n",
        "Avant d'ajouter nos nouvelles couches au [modèle pré-entraîné] (https://developers.google.com/machine-learning/glossary#pre-trained-model), nous devons franchir une étape importante : **figer les couches pré-entraînées du modèle**. \n",
        "\n",
        "Cela signifie que lors de l'entraînement, nous ne mettrons pas à jour les couches de base du modèle pré-entraîné. Au lieu de cela, nous ne mettrons à jour que les nouvelles couches que nous ajouterons à la fin pour notre nouvelle classification. Nous figeons les couches initiales parce que nous voulons conserver l'apprentissage réalisé lors de l'entraînement sur l'ensemble de données ImageNet. Si elles étaient \"dégelées\" à ce stade, nous détruirions probablement ces précieuses informations. Il sera possible de débloquer et d'entraîner ces couches ultérieurement, dans le cadre d'un processus appelé \"réglage fin\".\n",
        "\n",
        "Geler les couches de base est aussi simple que de régler la possibilité d'entraînement sur le modèle à `False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIetGVbOgD5y"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hc-ngyXgD5y"
      },
      "source": [
        "## Addition de nouvelles couches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3NNwx0WgD5z"
      },
      "source": [
        "Nous pouvons maintenant ajouter les nouvelles couches entraînables au modèle pré-entraîné. Elles prendront les caractéristiques des couches pré-entraînées et les transformeront en prédictions sur le nouvel ensemble de données. \n",
        "\n",
        "Nous allons ajouter deux couches au modèle: \n",
        "* La première sera une couche de mise en commun, comme nous l'avons vu dans notre [réseau neuronal convolutif] précédent (https://developers.google.com/machine-learning/glossary#convolutional_layer). (Si vous souhaitez mieux comprendre le rôle des couches de mise en commun dans les CNN, lisez [cet article de blog détaillé] (https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/#:~:text=A%20pooling%20layer%20is%20a,Convolutional%20Layer)). \n",
        "* Nous devons ensuite ajouter notre couche finale, qui classera Bo ou non Bo. Il s'agira d'une couche densément connectée avec une sortie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT3_xBHkgD5z"
      },
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "# Separately from setting trainable on the model, we set training to False \n",
        "x = base_model(inputs, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbsq2sStgD5z"
      },
      "source": [
        "Jetons un coup d'œil au modèle, maintenant que nous avons combiné le modèle pré-entraîné avec les nouvelles couches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gb2tUrFgD5z"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXRNwgz5gD50"
      },
      "source": [
        "Keras nous donne un bon résumé ici, car il montre le modèle pré-entraîné vgg16 comme une seule unité, plutôt que de montrer toutes les couches internes. Il est également intéressant de noter que nous avons de nombreux paramètres non entraînables car nous avons figé le modèle pré-entraîné."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rohbn7mtgD50"
      },
      "source": [
        "## Compilation du Modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls6nhT0SgD50"
      },
      "source": [
        "Comme dans nos exercices précédents, nous devons compiler le modèle avec les options de pertes et de métriques. Nous devons ici faire des choix différents. Dans les cas précédents, notre problème de classification comportait de nombreuses catégories. Par conséquent, nous avons choisi l'entropie croisée catégorielle pour le calcul de notre perte. \n",
        "\n",
        "Dans le cas présent, nous n'avons qu'un problème de classification binaire (**Bo** ou **non Bo**) et nous utiliserons donc [l'entropie croisée binaire] (https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy). Pour plus de détails sur les différences entre les deux, voir [ici] (https://gombru.github.io/2018/05/23/cross_entropy_loss/). Nous utiliserons également la précision binaire au lieu de la précision traditionnelle.\n",
        "\n",
        "En réglant `from_logits=True`, nous informons à la [fonction de perte] (https://gombru.github.io/2018/05/23/cross_entropy_loss/) que les valeurs de sortie ne sont pas normalisées (par exemple avec softmax)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn8W5DGQgD51"
      },
      "source": [
        "# Important to use binary crossentropy and binary accuracy as we now have a binary classification problem\n",
        "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExS0pxStgD51"
      },
      "source": [
        "## Augmentation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWzKpH3YgD51"
      },
      "source": [
        "Comme nous avons affaire à un très petit ensemble de données (juste 30 images de Bo), il est particulièrement important d'augmenter nos données. \n",
        "\n",
        "La procédure d'augmentation de données est une méthode où nous apporterons de petites modifications aux images existantes, ce qui permettra au modèle d'apprendre à partir d'une plus grande variété d'images. Cela l'aidera à apprendre à reconnaître de nouvelles images de Bo au lieu de se contenter de mémoriser les images sur lesquelles il apparaît.\n",
        "\n",
        "Afin de faire cette augmentation, nous allons utiliser un générateur d'images qui va faire des opérations variées sur les images existantes. Parmi celles que vous utilisez ci-dessous, on trouve : \n",
        "* rotation (10 degrées à gauche ou à droite)\n",
        "* zoom (10%)\n",
        "* décalage des images (horizontal et vertical, 10% de la taille)\n",
        "* effet miroir (horizontal seulement)\n",
        "\n",
        "Ces transformations une fois combinées, permettent de créer plusieurs images différentes qui permettent de généraliser l'entraînement (par exemple, en mettant Bo \"hors centre\" de l'image).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuBo9ZoYgD51"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# create a data generator\n",
        "datagen = ImageDataGenerator(\n",
        "        samplewise_center=True,  # set each sample mean to 0\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-SGjcFegD51"
      },
      "source": [
        "## Chargement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udi_HrwYgD52"
      },
      "source": [
        "Jusqu'à présent, nous avons vu des ensembles de données sous différents formats. Dans l'exercice MNIST, nous avons pu télécharger l'ensemble de données directement à partir de la bibliothèque Keras. \n",
        "\n",
        "Pour cet exercice, nous allons charger des images directement à partir de dossiers en utilisant la fonction [`flow_from_directory`](https://keras.io/api/preprocessing/image/) de Keras. Nous avons configuré nos répertoires pour faciliter le processus, car nos étiquettes sont déduites des noms de dossiers. \n",
        "\n",
        "Dans le répertoire `data/presidential_doggy_door`, nous avons les répertoires train et validation, qui contiennent chacun des dossiers pour les images de Bo et non Bo. Dans les répertoires not_bo, nous avons des images d'autres chiens et chats, pour apprendre à notre modèle à exclure les autres animaux. N'hésitez pas à explorer les images pour vous faire une idée de notre ensemble de données.\n",
        "\n",
        "Notez que [flow_from_directory](https://keras.io/api/preprocessing/image/) nous permet également de dimensionner nos images en fonction du modèle : 244x244 pixels avec 3 canaux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9LRMTNJgD52"
      },
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory('data/presidential_doggy_door/train/', \n",
        "                                       target_size=(224, 224), \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode='binary', \n",
        "                                       batch_size=8)\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen.flow_from_directory('data/presidential_doggy_door/valid/', \n",
        "                                      target_size=(224, 224), \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode='binary', \n",
        "                                      batch_size=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Pgp9jcgD52"
      },
      "source": [
        "## Entraîner le modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URDjzIOHgD52"
      },
      "source": [
        "Il est temps d'entraîner notre modèle et de voir comment il se comporte. Rappelons que lors de l'utilisation d'un générateur de données, nous devons explicitement définir le nombre de `steps_per_epoch` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im7BggMfgD53"
      },
      "source": [
        "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1udDLCDKgD53"
      },
      "source": [
        "## Discussion sur les résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nun3S5lxgD53"
      },
      "source": [
        "La précision de l'entraînement et de la validation que vous avez obtenu doivent être assez élevée. \n",
        "\n",
        "C'est un résultat assez impressionnant compte tenu du petit ensemble de données. Frâce aux connaissances transférées du modèle ImageNet, il a pu atteindre une précision élevée et bien se généraliser. Cela signifie qu'il a une très bonne perception de Bo et des animaux domestiques qui ne sont pas Bo.\n",
        "\n",
        "Si vous avez constaté une certaine fluctuation dans la précision de la validation, ce n'est pas grave non plus. Nous avons une technique pour améliorer notre modèle dans la section suivante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nghXj-mgD53"
      },
      "source": [
        "## Réglage fin du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGMnqDbdgD53"
      },
      "source": [
        "Maintenant que les nouvelles couches du modèle sont formées, nous avons la possibilité d'appliquer une dernière astuce pour améliorer le modèle, appelée [fine-tuning] (https://developers.google.com/machine-learning/glossary#f). Pour ce faire, nous débloquons l'ensemble du modèle et l'entraînons à nouveau avec un [taux d'apprentissage] très faible (https://developers.google.com/machine-learning/glossary#learning-rate). Ainsi, les couches préentraînées de base prendront de très petites mesures et s'ajusteront légèrement, améliorant ainsi le modèle dans une faible mesure (on aime grapiller des 0.001%).  \n",
        "\n",
        "Notez qu'il est important de ne procéder à cette étape qu'une fois que le modèle avec les couches gelées a été entièrement entraîné. Les couches de mise en commun et de classification non entraînées que nous avons ajoutées au modèle plus tôt ont été initialisées de manière aléatoire. Cela signifie qu'elles ont dû être mises à jour assez souvent pour classer correctement les images. Par le biais du processus de [rétropropagation] (https://developers.google.com/machine-learning/glossary#backpropagation), des mises à jour initiales importantes dans les dernières couches auraient entraîné des mises à jour potentiellement importantes dans les couches pré-entraînées également. Ces mises à jour auraient détruit ces importantes caractéristiques pré-entraînées. Cependant, maintenant que les dernières couches sont entraînées et ont convergé, toute mise à jour du modèle dans son ensemble sera beaucoup plus petite (en particulier avec un taux d'apprentissage très faible) et ne détruira pas les caractéristiques des couches précédentes.\n",
        "\n",
        "Essayons de dégeler les couches pré-entraînées, puis d'affiner le modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sxwPD8pgD54"
      },
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "# to the `trainable` attribute of any inner layer, so that your changes\n",
        "# are taken into account\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5JLbHSdgD54"
      },
      "source": [
        "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eeac1FYgD54"
      },
      "source": [
        "## Examiner les prédictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGfW9sVWgD54"
      },
      "source": [
        "Maintenant que nous avons un modèle bien entraîné, il est temps de créer notre porte pour chien pour Bo ! Nous pouvons commencer par examiner les prédictions du modèle. Nous allons prétraiter l'image de la même manière que nous l'avons fait pour notre dernière porte pour chien."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtPCxFWOgD55"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "def show_image(image_path):\n",
        "    image = mpimg.imread(image_path)\n",
        "    plt.imshow(image)\n",
        "\n",
        "def make_predictions(image_path):\n",
        "    show_image(image_path)\n",
        "    image = image_utils.load_img(image_path, target_size=(224, 224))\n",
        "    image = image_utils.img_to_array(image)\n",
        "    image = image.reshape(1,224,224,3)\n",
        "    image = preprocess_input(image)\n",
        "    preds = model.predict(image)\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBPG7kH6gD55"
      },
      "source": [
        "Essayons avec quelques images :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMhSMzNRgD55"
      },
      "source": [
        "make_predictions('data/presidential_doggy_door/valid/bo/bo_20.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ImWgzL4gD55"
      },
      "source": [
        "make_predictions('data/presidential_doggy_door/valid/not_bo/121.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X5GtGJtgD55"
      },
      "source": [
        "Ici, il semble qu'un nombre négatif signifie qu'il s'agit de Bo et qu'un nombre positif signifie qu'il s'agit d'autre chose. Nous pouvons utiliser cette information pour que notre porte pour chien ne laisse entrer que Bo !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUM1et9vgD56"
      },
      "source": [
        "## Exercice : Créer une porte automatique pour Bo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "769ht2B2gD56"
      },
      "source": [
        "Complétez le code suivant (FILLME) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5mbxghgD56"
      },
      "source": [
        "def presidential_doggy_door(image_path):\n",
        "    preds = make_predictions(image_path)\n",
        "    if preds[0]< FILLME:\n",
        "        print(\"It's Bo! Let him in!\")\n",
        "    else:\n",
        "        print(\"That's not Bo! Stay out!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nge1wnIegD56"
      },
      "source": [
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym2LtaQgD57"
      },
      "source": [
        "presidential_doggy_door('data/presidential_doggy_door/valid/not_bo/131.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY16f7rVgD57"
      },
      "source": [
        "presidential_doggy_door('data/presidential_doggy_door/valid/bo/bo_29.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzit2kJtgD57"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYsY8xifgD57"
      },
      "source": [
        "Excellent travail ! Avec l'apprentissage par transfert, vous avez construit un modèle très précis à partir d'un très petit ensemble de données. Cette technique peut être extrêmement puissante et faire la différence entre un projet réussi et un projet qui n'arrive pas à décoller. Nous espérons que ces techniques vous aideront à l'avenir dans des situations similaires !"
      ]
    }
  ]
}