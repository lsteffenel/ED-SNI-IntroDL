{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "TP1_Some_basics_about_learning_process.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/ED-SNI-IntroDL/blob/main/02_Introduction_a_Keras_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construire un modèle de réseaux de neurones avec Keras\n",
        "\n",
        "Keras est une bibliothèque \"haut niveau\" utilisée pour simplifier la description de modèles de réseaux de neurones sur Tensorflow (bibliothèque IA de Google). L'avantage surtout est de pouvoir utiliser des GPU pour accélérer le calcul.\n",
        "\n",
        "Le travail avec Keras suit un cheminement similaires à celui avec Scikit-Learn, mais il y a quelques différences à retenir."
      ],
      "metadata": {
        "id": "EpQRZSswWmWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import numpy as np\n",
        "print (tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "nO3TA6f7WmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le paragraphe suivant vous avez certainement eu un message d'erreur indiquant que vous n'avez pas des GPU. Dans ce cas, Keras utilisera la CPU de la machine.\n",
        "\n",
        "## Chargement de données\n",
        "\n",
        "Tout comme Scikit-Learn, Keras a aussi un ensemble de datasets prêt à utilisation pour des exemples. Dans le cas suivant, nous allons charger le dataset MNIST (écriture à la main) et le séparer en deux groupes : Train et Test. Les données de validation (vérification pendant l'entraînement) seront séparés du groupe Train plus tard."
      ],
      "metadata": {
        "id": "5eYo87D2WmWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "q2eLH6ACWmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce dataset, nous avons 70000 images. 60000 images sont utilisées pour l'entraînement, et 10000 pour l'ensemble de `test`. On peut visualiser les \"dimensions\" de chacun des ensembles :\n",
        "- les ensembles \"x\" contiennent les données. On trouve respectivement 60000 et 10000 matrices 28x28.\n",
        "- les ensembles \"y\" contiennent juste les résultats attendus (appelés \"étiquettes\" ou \"label\"). On trouve également 60000 et 10000 lignes. Comme les résultats se trouvent sur une \"colonne\", on n'a pas besoin d'indiquer la dimension \"1\" pour celle-ci.\n"
      ],
      "metadata": {
        "id": "OqYaTmDwOg97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "odgDUCJSWmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut également voir le contenu des ensembles. Ici, on affiche `y_train` (l'affichage est tronquée)."
      ],
      "metadata": {
        "id": "y1ZrSV3vQhQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "iOXq4OkDWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme on vient de voir, les données de MNIST se présentent sous la forme d'images 28x28 pixels. Ceux-ci peuvent avoir des valeurs de 0 à 255, correspondant à 256 tons de gris. Les labels (`y_train`, par exemple) correspondent aux caractères représentés : les chiffres 0 à 9.\n",
        "\n",
        "Le paragraphe suivant définit une fonction permettant de visualiser ce dataset."
      ],
      "metadata": {
        "id": "8cNaXhPsWmWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def plot_images(x,y=None, indices='all', columns=12, x_size=1, y_size=1,\n",
        "                colorbar=False, y_pred=None, cm='binary', norm=None, y_padding=0.35, spines_alpha=1,\n",
        "                fontsize=20, interpolation='lanczos', save_as='auto'):\n",
        "    \"\"\"\n",
        "    Show some images in a grid, with legends\n",
        "    args:\n",
        "        x             : images - Shapes must be (-1,lx,ly) (-1,lx,ly,1) or (-1,lx,ly,3),(-1,1,lx,ly) or (-1,3,lx,ly)\n",
        "        y             : real classes or labels or None (None)\n",
        "        indices       : indices of images to show or 'all' for all ('all')\n",
        "        columns       : number of columns (12)\n",
        "        x_size,y_size : figure size (1), (1)\n",
        "        colorbar      : show colorbar (False)\n",
        "        y_pred        : predicted classes (None)\n",
        "        cm            : Matplotlib color map (binary)\n",
        "        norm          : Matplotlib imshow normalization (None)\n",
        "        y_padding     : Padding / rows (0.35)\n",
        "        spines_alpha  : Spines alpha (1.)\n",
        "        font_size     : Font size in px (20)\n",
        "        save_as       : Filename to use if save figs is enable ('auto')\n",
        "    returns:\n",
        "        nothing\n",
        "    \"\"\"\n",
        "    if indices=='all': indices=range(len(x))\n",
        "    if norm and len(norm) == 2: norm = matplotlib.colors.Normalize(vmin=norm[0], vmax=norm[1])\n",
        "    draw_labels = (y is not None)\n",
        "    draw_pred   = (y_pred is not None)\n",
        "    # Torch Tensor ?\n",
        "    if y.__class__.__name__      == 'Tensor': y=y.numpy()\n",
        "    if y_pred.__class__.__name__ == 'Tensor': y_pred=y_pred.detach().numpy()\n",
        "\n",
        "    rows        = math.ceil(len(indices)/columns)\n",
        "    fig=plt.figure(figsize=(columns*x_size, rows*(y_size+y_padding)))\n",
        "    n=1\n",
        "    for i in indices:\n",
        "        axs=fig.add_subplot(rows, columns, n)\n",
        "        n+=1\n",
        "        # ---- Shape is (lx,ly)\n",
        "        if len(x[i].shape)==2:\n",
        "            xx=x[i]\n",
        "        # ---- Shape is (lx,ly,c) or (c,lx,ly)\n",
        "        if len(x[i].shape)==3:\n",
        "            if x[i].__class__.__name__ == 'Tensor':\n",
        "               (c,lx,ly)=x[i].shape\n",
        "               if c==1:\n",
        "                   xx=x[i].permute(1,2,0).numpy().reshape(lx,ly)\n",
        "               else:\n",
        "                   xx=x[i].permute(1,2,0).numpy() #---> (lx,ly,n)\n",
        "            else:\n",
        "                (lx,ly,c)=x[i].shape\n",
        "                if c==1:\n",
        "                    xx=x[i].reshape(lx,ly)\n",
        "                else:\n",
        "                    xx=x[i]\n",
        "\n",
        "        img=axs.imshow(xx,   cmap = cm, norm=norm, interpolation=interpolation)\n",
        "        axs.spines['right'].set_visible(True)\n",
        "        axs.spines['left'].set_visible(True)\n",
        "        axs.spines['top'].set_visible(True)\n",
        "        axs.spines['bottom'].set_visible(True)\n",
        "        axs.spines['right'].set_alpha(spines_alpha)\n",
        "        axs.spines['left'].set_alpha(spines_alpha)\n",
        "        axs.spines['top'].set_alpha(spines_alpha)\n",
        "        axs.spines['bottom'].set_alpha(spines_alpha)\n",
        "        axs.set_yticks([])\n",
        "        axs.set_xticks([])\n",
        "        if draw_labels and not draw_pred:\n",
        "            axs.set_xlabel(y[i],fontsize=fontsize)\n",
        "        if draw_labels and draw_pred:\n",
        "            if y[i]!=y_pred[i]:\n",
        "                axs.set_xlabel(f'{y_pred[i]} ({y[i]})',fontsize=fontsize)\n",
        "                axs.xaxis.label.set_color('red')\n",
        "            else:\n",
        "                axs.set_xlabel(y[i],fontsize=fontsize)\n",
        "        if colorbar:\n",
        "            fig.colorbar(img,orientation=\"vertical\", shrink=0.65)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DlffLJa0u_Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarquez le \"label\" correspondant sous chaque image."
      ],
      "metadata": {
        "id": "AW52c1d3O5T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(x_train, y_train, range(5,41), columns=12)"
      ],
      "metadata": {
        "id": "IxLub7eGwc7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[27])\n",
        "plot_images(x_train, y_train, indices=[27],  x_size=5,y_size=5, colorbar=True)"
      ],
      "metadata": {
        "id": "pVreIwymYfz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les paragraphes suivants font plusieurs opérations afin de préparer les données :"
      ],
      "metadata": {
        "id": "Uan9xLhZO5T_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 - Transformation et normalisation des données**\n",
        "\n",
        "Les valeurs de base son des entiers entre 0 et 255 pour représenter les 256 tons de gris. La majorité des algorithmes utilisent des valeurs réels, de préférence dans la fourchette 0 à 1 ou -1 à 1.\n",
        "\n",
        "Les paragraphes suivantes modifient le type des données (`float32`) puis font une normalisation simple (diviser la valeur par `max`, qui dans ce cas doît être de 255). Bien sûr, d'autres méthodes de normalisation plus élaborées sont possibles, mais ça suffit pour l'instant."
      ],
      "metadata": {
        "id": "pSIUUpzqO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "trusted": true,
        "id": "RQp1Q6ADO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before normalization : Min={}, max={}'.format(x_train.min(),x_train.max()))\n",
        "\n",
        "xmax=x_train.max()\n",
        "x_train = x_train / xmax\n",
        "x_test  = x_test  / xmax\n",
        "\n",
        "print('After normalization  : Min={}, max={}'.format(x_train.min(),x_train.max()))"
      ],
      "metadata": {
        "id": "VmnVPnqHYnvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 - Transformer les données catégoriques**\n",
        "Lorsqu'on a des données catégoriques (texte ou numéros), il faut les transformer afin d'éviter des mauvaises compréhensions de la part de l'algorithme (par exemple, supposer que une classe 2 vient toujours après une classe 1). Dans notre cas, nous allons transformer les classes 0 à 9 en représentations numériques (similaire à HotOneEncoder de Sklearn), afin de rendre indépendantes ces classes."
      ],
      "metadata": {
        "id": "qz-IyPVqO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_hotone = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test_hotone = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AgI0qRWrO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hotone"
      ],
      "metadata": {
        "id": "5RGjh84XWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La Création d'un modèle\n",
        "\n",
        "Keras a plusieurs modes permettant la création de modèles de réseaux de neurones. Dans ce cas, nous allons utiliser l'API `Sequential` qui permet de décrire couche par couche du réseau et les empiler (grâce à `add()`).\n",
        "\n",
        "Nous allons faire un modèle simple avec des réseaux denses (totalement connectés). La première couche définit la taille de l'entrée (les 784 valeurs reçus du dataset), les autres utilisent par défaut la taille de la sortie de la couche précédente. Egalement, nous indiquons que chaque couche comptera avec 10 neurones.\n",
        "\n",
        "Finalement, remarquez qu'on utilise deux types de fonction d'activation, sigmoid et softmax.\n",
        "Pour simplifier la description, sigmoid donne une probabilité entre 0 et 1, alors que Softmax affiche \"1\" sur la sortie avec la plus grande probabilité et \"0\" sur les autres. C'est pour cela qu'on utilise Softmax à la sortie, ça permet d'avoir un résultat plutôt qu'une liste de probabilités."
      ],
      "metadata": {
        "id": "hXtTapcTO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "# Declaration du modèle en Keras\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Input((28,28)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(30, activation='sigmoid'))\n",
        "model.add(layers.Dense(20, activation='sigmoid'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "U9XLxq-BWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entraînement du modèle\n",
        "\n",
        "Une fois défini le modèle, il faut l'entraîner avec les données.\n",
        "Le paragraphe suivant définit les hyperparamètres du modèle, dont le `batch_size`(taille des sous-ensembles utilisés dans la descente de gradient), le nombre d'epochs (parcours de l'ensemble de données d'entraînement).\n",
        "\n",
        "L'appel à compile indique aussi qu'on utilise le modèle de descente de gradient SGD (il y a plusieurs), que la métrique utilisée est l'accuracy (métrique qui correspond à (TP+TN)/(TP+TN+FP+FN)), et que la fonction de perte est la `categorical_crossentropy`, une fonction qui compare les probabilités pour des labels catégoriques."
      ],
      "metadata": {
        "id": "pg4Axb4GO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "#num_classes = 10\n",
        "epochs= 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  optimizer='SGD',  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "32wR8ClWWmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalement, on lance l'entraînement. Remarquez aussi qu'on n'a pas crée des données Validation avant, on le fera ici en réservant 10% des données de Train (appel à `validation_split=0.1`).\n",
        "\n",
        "Comme le dataset est simple, on peut faire 50 epoch même sans un GPU."
      ],
      "metadata": {
        "id": "1A-EfnLBO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train_hotone, batch_size=batch_size, epochs=epochs, validation_split=0.1,verbose=1 )\n",
        "\n",
        "#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
        "# Je vous invite à lire la documentation : https://keras.io/models/sequential/"
      ],
      "metadata": {
        "id": "Jng3P9z1WmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les paragraphes suivants nous permettent de voir comment le modèle améliore sa performance au fil des epochs"
      ],
      "metadata": {
        "id": "Y-bcqc4zO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, figsize=(8,6),\n",
        "                 plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']}):\n",
        "    \"\"\"\n",
        "    Show history\n",
        "    args:\n",
        "        history: history\n",
        "        figsize: fig size\n",
        "        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n",
        "    \"\"\"\n",
        "    fig_id=0\n",
        "    for title,curves in plot.items():\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.title(title)\n",
        "        plt.ylabel(title)\n",
        "        plt.xlabel('Epoch')\n",
        "        for c in curves:\n",
        "            plt.plot(history.history[c])\n",
        "        plt.legend(curves, loc='upper left')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mrjA4FOuO5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history, figsize=(6,4))"
      ],
      "metadata": {
        "trusted": true,
        "id": "QKhT0-sOO5UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, on peut estimer la performance du modèle avec les données Test.\n",
        "\n",
        "Comparez ces valeur avec ceux de l'entraînement (`val_loss` et `val_accuracy`\n",
        " ci-dessus)."
      ],
      "metadata": {
        "id": "TGLQHMDPO5UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test_hotone,verbose=0)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "qTbNPwg6WmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ces résultats montrent que le modèle se porte un peu moins bien avec de nouvelles données, mais ça reste intéressant."
      ],
      "metadata": {
        "id": "zMgRWzJsO5UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Des erreurs malgré tout\n",
        "\n",
        "Si vous avez fait attention, on n'a toujours pas touché le dataset x_test/y_test, vu qu'on a fait l'entraînement avec 90% de x_train et validé avec les 10% restants.\n",
        "\n",
        "On peut donc utiliser x_test comme \"nouvelle donnée\" et vérifier si notre modèle rend bien les réponses.\n",
        "\n",
        "Dans le prochain paragraphe nous allons donc produire une estimation y_pred à partir de x_test. Comme la sortie du modèle est un array de 10 positions (notre y_train_hotone), on passe ce résultat à np.argmax() pour obtenir juste le numéro de la classe."
      ],
      "metadata": {
        "id": "c03yfesXZd_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d'abord, on utilise le modèle pour faire une prévision sur l'ensemble de test\n",
        "# Ça retourne une liste avec 10 colonnes (une par sortie possible).\n",
        "y_pred_hotone = model.predict(x_test)\n",
        "\n",
        "# avec la fonction argmax, on ne garde que l'index de la colonne avec la plus grande valeur\n",
        "y_pred    = np.argmax(y_pred_hotone, axis=-1)"
      ],
      "metadata": {
        "id": "0dml1fnaZx1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, on affiche quelques éléments, avec la valeur prédite et la valeur attendue (entre parenthèses). Vous pouvez vérifier que quelques prédictions sont incorrectes."
      ],
      "metadata": {
        "id": "NuQxzGyZZ1Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(x_test, y_test, range(0,200), columns=12, x_size=1, y_size=1, y_pred=y_pred)"
      ],
      "metadata": {
        "id": "I2sqX05jZ61q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice :\n",
        "On a obtenu avec ce modèle basique, un taux d'accuracy supérieur à 80%.\n",
        "- Essayer de modifier le nombre de neurones et des couches intermédiaires. Est-ce que ça améliore la précision du modèle ?\n",
        "\n"
      ],
      "metadata": {
        "id": "0G4jaLW6WmWL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w71zOKWmVBZf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}