{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "TP1_Some_basics_about_learning_process.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/ED-SNI-IntroDL/blob/main/02_Introduction_a_Keras_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lsteffenel/ED-SNI-IntroDL/blob/main/02_Introduction_a_Keras_MNIST.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "X9_vAfiHPAjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construire un modèle de réseaux de neurones avec Keras\n",
        "\n",
        "Keras est une bibliothèque \"haut niveau\" utilisée pour simplifier la description de modèles de réseaux de neurones sur Tensorflow (bibliothèque IA de Google). L'avantage surtout est de pouvoir utiliser des GPU pour accélérer le calcul.\n",
        "\n",
        "Le travail avec Keras suit un cheminement similaires à celui avec Scikit-Learn, mais il y a quelques différences à retenir."
      ],
      "metadata": {
        "id": "EpQRZSswWmWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "print (tf.__version__)\n"
      ],
      "metadata": {
        "id": "nO3TA6f7WmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le paragraphe suivant vous avez certainement eu un message d'erreur indiquant que vous n'avez pas des GPU. Dans ce cas, Keras utilisera la CPU de la machine.\n",
        "\n",
        "## Chargement de données\n",
        "\n",
        "Tout comme Scikit-Learn, Keras a aussi un ensemble de datasets prêt à utilisation pour des exemples. Dans le cas suivant, nous allons charger le dataset MNIST (écriture à la main) et le séparer en deux groupes : Train et Test. Les données de validation (vérification pendant l'entraînement) seront séparés du groupe Train plus tard."
      ],
      "metadata": {
        "id": "5eYo87D2WmWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "q2eLH6ACWmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce dataset, nous avons 70000 images. 60000 images sont utilisées pour l'entraînement, et 10000 pour l'ensemble de `test`. On peut visualiser les \"dimensions\" de chacun des ensembles :\n",
        "- les ensembles \"x\" contiennent les données. On trouve respectivement 60000 et 10000 matrices 28x28.\n",
        "- les ensembles \"y\" contiennent juste les résultats attendus (appelés \"étiquettes\" ou \"label\"). On trouve également 60000 et 10000 lignes. Comme les résultats se trouvent sur une \"colonne\", on n'a pas besoin d'indiquer la dimension \"1\" pour celle-ci.\n"
      ],
      "metadata": {
        "id": "OqYaTmDwOg97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "odgDUCJSWmWJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut également voir le contenu des ensembles. Ici, on affiche `y_train` (l'affichage est tronquée)."
      ],
      "metadata": {
        "id": "y1ZrSV3vQhQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "iOXq4OkDWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme on vient de voir, les données de MNIST se présentent sous la forme d'images 28x28 pixels. Ceux-ci peuvent avoir des valeurs de 0 à 255, correspondant à 256 tons de gris. Les labels (`y_train`, par exemple) correspondent aux caractères représentés : les chiffres 0 à 9.\n",
        "\n",
        "Le paragraphe suivant définit une fonction permettant de visualiser ce dataset."
      ],
      "metadata": {
        "id": "8cNaXhPsWmWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def plot_images(x,y=None,y_pred=None):\n",
        "  nrows=3\n",
        "  ncols=4\n",
        "  draw_labels = (y is not None)\n",
        "  draw_pred   = (y_pred is not None)\n",
        "\n",
        "  fig, axs = plt.subplots(nrows, ncols, layout=None)\n",
        "  indices = random.sample(range(0,1000),nrows*ncols)\n",
        "  i = 0\n",
        "  for ax in axs.flat:\n",
        "    ax.imshow(x[indices[i]])\n",
        "    if not draw_labels and not draw_pred:\n",
        "      ax.set_xlabel(indices[i], fontsize=12)\n",
        "    if draw_labels and not draw_pred:\n",
        "      ax.set_xlabel(y[indices[i]], fontsize=12)\n",
        "    if draw_labels and draw_pred:\n",
        "      pred = str(y_pred[indices[i]])+' ('+str(y[indices[i]])+')'\n",
        "      color = 'red' if y_pred[indices[i]] != y[indices[i]] else 'black'\n",
        "      ax.set_xlabel(pred, fontsize=12, color=color)\n",
        "    i+=1\n",
        "  plt.subplots_adjust(hspace=0.3)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DlffLJa0u_Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarquez le \"label\" correspondant sous chaque image."
      ],
      "metadata": {
        "id": "AW52c1d3O5T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(x_train,y_train,y_train)"
      ],
      "metadata": {
        "id": "IxLub7eGwc7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les paragraphes suivants font plusieurs opérations afin de préparer les données :\n",
        "\n",
        "**1 - Reformater les données**\n",
        "\n",
        "Dans un réseau de neurones dense (DNN), chaque neurone reçoit l'ensemble des données. Pour simplifier cela, les images 28x28 seront \"applaties\" en un seul array unidimensionnel de 784 valeurs"
      ],
      "metadata": {
        "id": "Uan9xLhZO5T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784) #  28*28\n",
        "x_test = x_test.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "vJ-_e5bQWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 - Transformation et normalisation des données**\n",
        "\n",
        "Les valeurs de base son des entiers entre 0 et 255 pour représenter les 256 tons de gris. La majorité des algorithmes utilisent des valeurs réels, de préférence dans la fourchette 0 à 1 ou -1 à 1.\n",
        "\n",
        "Les paragraphes suivantes modifient le type des données (`float32`) puis font une normalisation simple (diviser la valeur par 255). Bien sûr, d'autres méthodes de normalisation plus élaborées sont possibles, mais ça suffit pour l'instant."
      ],
      "metadata": {
        "id": "pSIUUpzqO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "trusted": true,
        "id": "RQp1Q6ADO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "trusted": true,
        "id": "6QWNy_ePO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 - Transformer les données catégoriques**\n",
        "Lorsqu'on a des données catégoriques (texte ou numéros), il faut les transformer afin d'éviter des mauvaises compréhensions de la part de l'algorithme (par exemple, supposer que une classe 2 vient toujours après une classe 1). Dans notre cas, nous allons transformer les classes 0 à 9 en représentations numériques (similaire à HotOneEncoder de Sklearn), afin de rendre indépendantes ces classes."
      ],
      "metadata": {
        "id": "qz-IyPVqO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AgI0qRWrO5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "5RGjh84XWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La Création d'un modèle\n",
        "\n",
        "Keras a plusieurs modes permettant la création de modèles de réseaux de neurones. Dans ce cas, nous allons utiliser l'API `Sequential` qui permet de décrire couche par couche du réseau et les empiler (grâce à `add()`).\n",
        "\n",
        "Nous allons faire un modèle simple avec des réseaux denses (totalement connectés). La première couche définit la taille de l'entrée (les 784 valeurs reçus du dataset), les autres utilisent par défaut la taille de la sortie de la couche précédente. Egalement, nous indiquons que chaque couche comptera avec 10 neurones.\n",
        "\n",
        "Finalemen, remarquez qu'on utilise deux types de fonction d'activation, sigmoid et softmax.\n",
        "Pour simplifier la description, sigmoid donne une probabilité entre 0 et 1, alors que Softmax affiche \"1\" sur la sortie avec la plus grande probabilité et \"0\" sur les autres. C'est pour cela qu'on utilise Softmax à la sortie, ça permet d'avoir un résultat plutôt qu'une liste de probabilités."
      ],
      "metadata": {
        "id": "hXtTapcTO5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Declaration du modèle en Tensorflow2.0\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(20, activation='sigmoid', input_dim =(784)))\n",
        "model.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# résumé du modèle\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "U9XLxq-BWmWK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entraînement du modèle\n",
        "\n",
        "Une fois défini le modèle, il faut l'entraîner avec les données.\n",
        "Le paragraphe suivant définit les hyperparamètres du modèle, dont le `batch_size`(taille des sous-ensembles utilisés dans la descente de gradient), le nombre d'epochs (parcours de l'ensemble de données d'entraînement).\n",
        "\n",
        "L'appel à compile indique aussi qu'on utilise le modèle de descente de gradient SGD (il y a plusieurs), que la métrique utilisée est l'accuracy (métrique qui correspond à (TP+TN)/(TP+TN+FP+FN)), et que la fonction de perte est la `categorical_crossentropy`, une fonction qui compare les probabilités pour des labels catégoriques."
      ],
      "metadata": {
        "id": "pg4Axb4GO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "#num_classes = 10\n",
        "epochs= 50\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  optimizer='SGD',  metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "32wR8ClWWmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalement, on lance l'entraînement. Remarquez aussi qu'on n'a pas crée des données Validation avant, on le fera ici en réservant 10% des données de Train.\n",
        "\n",
        "Comme le dataset est simple, on peut faire 50 epoch même sans un GPU."
      ],
      "metadata": {
        "id": "1A-EfnLBO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,verbose=1 )\n",
        "\n",
        "#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
        "# Je vous invite à lire la documentation : https://keras.io/models/sequential/"
      ],
      "metadata": {
        "id": "Jng3P9z1WmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les paragraphes suivants nous permettent de voir comment le modèle améliore sa performance au fil des epochs"
      ],
      "metadata": {
        "id": "Y-bcqc4zO5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, figsize=(8,6),\n",
        "                 plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']}):\n",
        "    \"\"\"\n",
        "    Show history\n",
        "    args:\n",
        "        history: history\n",
        "        figsize: fig size\n",
        "        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n",
        "    \"\"\"\n",
        "    fig_id=0\n",
        "    for title,curves in plot.items():\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.title(title)\n",
        "        plt.ylabel(title)\n",
        "        plt.xlabel('Epoch')\n",
        "        for c in curves:\n",
        "            plt.plot(history.history[c])\n",
        "        plt.legend(curves, loc='upper left')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mrjA4FOuO5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history, figsize=(6,4))"
      ],
      "metadata": {
        "trusted": true,
        "id": "QKhT0-sOO5UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, on peut estimer la performance du modèle avec les données Test.\n",
        "\n",
        "Comparez ces valeur avec ceux de l'entraînement (`val_loss` et `val_accuracy`\n",
        " ci-dessus)."
      ],
      "metadata": {
        "id": "TGLQHMDPO5UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test,verbose=0)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "qTbNPwg6WmWL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ces résultats montrent que le modèle se porte un peu moins bien avec de nouvelles données, mais ça reste intéressant."
      ],
      "metadata": {
        "id": "zMgRWzJsO5UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice :\n",
        "On a obtenu avec ce modèle basique, un taux d'accuracy supérieur à 70%.\n",
        "- Essayer d'améliorer la performence du modèle, en modifiant les fonctions d'activation, ou/et en n ajoutant le nombre de neurones et des couches intermédiaires.\n",
        "\n"
      ],
      "metadata": {
        "id": "0G4jaLW6WmWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.reshape(10000, 28,28)\n",
        "# d'abord, on utilise le modèle pour faire une prévision sur l'ensemble de test\n",
        "# Ça retourne une liste avec 10 colonnes (une par sortie possible).\n",
        "y_sigmoid = model.predict(x_test.reshape(10000, 784))\n",
        "\n",
        "# avec la fonction argmax, on ne garde que l'index de la colonne avec la plus grande valeur\n",
        "y_pred    = np.argmax(y_sigmoid, axis=-1)\n",
        "y_test_labels = np.argmax(y_test, axis=-1)"
      ],
      "metadata": {
        "id": "94ywQWlvzOoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "w71zOKWmVBZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maintenant, on affiche quelques éléments, avec la valeur prédite et la valeur attendue (entre parenthèses)\n",
        "plot_images(x_test,y_test_labels,y_pred)"
      ],
      "metadata": {
        "id": "u_TTk0YGWmWL",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_77OUTHIO5UQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}