{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv8 Tutorial",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/ED-SNI-IntroDL/blob/main/06-Detect-Segment-YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "# Détection d'objets rapide avec YOLOv8\n",
        "\n",
        "Même si on peut créer nos propres architectures DeepLearning, souvent il y a des bibliothèques et outils prêts pour des usages spécifiques.\n",
        "\n",
        "La famille d'algorithmes YOLO est très connue par sa vitesse et précision pour des tâches de détection d'objets.\n",
        "\n",
        "Dans les exemples ci-dessous, vous allez simplent utiliser YOLOv8 pour identifier des objets dans une image (libre à vous de modifier l'image source).\n",
        "\n",
        "Deux modes seront utilisés :\n",
        "- En mode détection, nous allons identifier la \"zone\" de l'objet, qui sera imprimé avec une boîte. C'est la façon la plus rapide car on ne fait qu'identifier l'objet et la zone dans lequel il est présent\n",
        "- En mode segmentation sémantique, nous allons identifier chaque pixel appartenant à l'objet. Un masque de détection permet de connaître exactement où chaque objet se trouve, pas seulement sa zone.\n",
        "\n",
        "Plusieurs autres exemples sont possibles avec YOLO (par exemple, détection de la pose d'une personne - grâce à une esquelette virtuelle) mais ça c'est pour un usage plus spécifique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "installer la bibliothèque `ultralytics` avec `pip`, puis vérifier que l'installation s'est fait correctement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!pip install --quiet ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Détection\n",
        "\n",
        "Nous allons utiliser un modèle préexistant `yolov8n.pt`, déjà entraîné sur le dataset COCO.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "\n"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "\n",
        "result.save('bus_detection.jpg')  # display to screen"
      ],
      "metadata": {
        "id": "WRgbd_OdwnJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "img = np.asarray(Image.open('bus_detection.jpg'))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uERt6HuEyB_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Ségmentation\n",
        "\n",
        "Cette fois-ci, c'est un modèle de ségmentation `yolov8n-seg.pt` (aussi pré-entraîné avec COCO) qui sera utilisé.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "modelseg = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "modelseg.train(data='coco8-seg.yaml', epochs=3)  # train the model\n",
        "segresults = modelseg('https://ultralytics.com/images/bus.jpg')  # predict on an image\n"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random\n",
        "\n",
        "# if you want all classes\n",
        "yolo_classes = list(model.names.values())\n",
        "classes_ids = [yolo_classes.index(clas) for clas in yolo_classes]\n",
        "\n",
        "img_pil = Image.open('bus.jpg')\n",
        "img = np.asarray(img_pil).copy() # Make a writable copy\n",
        "# Convert from RGB (PIL default) to BGR (OpenCV default)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "colors = [random.choices(range(256), k=3) for _ in classes_ids]\n",
        "for result in segresults:\n",
        "    for mask, box in zip(result.masks.xy, result.boxes):\n",
        "        points = np.int32([mask])\n",
        "        color_number = classes_ids.index(int(box.cls[0]))\n",
        "        cv2.fillPoly(img, points, colors[color_number])\n",
        "cv2.imwrite(\"bus_segmentation.jpg\",img)"
      ],
      "metadata": {
        "id": "pE9wqQ3jy--Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "img = np.asarray(Image.open('bus_segmentation.jpg'))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3ty11Rvk2hoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}