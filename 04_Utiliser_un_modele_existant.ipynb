{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "09-Utiliser_un_modele_existant.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ATTENTION\n",
        "\n",
        "Ce Notebook nécessite des ressources GPU. "
      ],
      "metadata": {
        "id": "PFkmYEo2rJj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lsteffenel/ED-SNI-IntroDL/blob/main/04_Utiliser_un_modele_existant.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "oWKPLKymJUFC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND_BGLHBbXpm"
      },
      "source": [
        "# Utiliser des modèles pré-entraînés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXyzqU8RbXpm"
      },
      "source": [
        "Bien qu'il soit souvent nécessaire de disposer d'un grand ensemble de données bien annotées pour résoudre un défi d'apprentissage profond, il existe de nombreux modèles pré-entraînés disponibles gratuitement que nous pouvons télécharger et utiliser directement. \n",
        "\n",
        "Lorsque vous décidez de vous lancer dans votre propre projet d'apprentissage profond, c'est une bonne idée de commencer par rechercher des modèles existants en ligne qui peuvent vous aider à atteindre votre objectif.\n",
        "\n",
        "Plusieurs répositoires disponibilisent des modèles pré-entraînés, comme par exemple TensorFlow Hub et [NGC](https://ngc.nvidia.com/catalog/models). Github contient aussi plusieurs projets qui rendent leurs modèles disponibles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5Lh0o5DbXpn"
      },
      "source": [
        "## Objectifs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1KS9-9AbXpo"
      },
      "source": [
        "* Utiliser Keras pour charger un modèle pré-entraîné\n",
        "* Prétraiter vos propres images pour travailler avec le modèle pré-entraîné\n",
        "* Utilisez le modèle pré-entraîné pour effectuer une inférence précise sur vos propres images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox8AbKAxbXpo"
      },
      "source": [
        "## Une porte automatisée pour chiens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYc5Me5GbXpp"
      },
      "source": [
        "Dans cette section, nous allons créer une porte pour chiens qui ne laisse entrer et sortir que les chiens (et non les autres animaux). Ainsi, nous pouvons garder nos chats à l'intérieur et les autres animaux à l'extérieur, là où ils doivent être. En utilisant les techniques abordées jusqu'à présent, nous aurions besoin d'un très grand ensemble de données contenant des photos de nombreux chiens, ainsi que d'autres animaux. Heureusement, il existe un modèle facilement disponible qui a été entraîné sur un vaste ensemble de données comprenant de nombreux animaux. \n",
        "\n",
        "Le [défi ImageNet] (https://en.wikipedia.org/wiki/ImageNet#History_of_the_ImageNet_challenge) a produit de nombreux modèles de pointe pouvant être utilisés pour la classification d'images. Ils ont été entraînés sur des millions d'images et peuvent classer avec précision des images dans 1 000 catégories différentes. Un grand nombre de ces catégories sont des animaux, y compris des races de chiens et de chats. Il s'agit d'un modèle parfait pour notre porte pour chien.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6_GfL-WbXpq"
      },
      "source": [
        "## Télécharger le modèle pré-entraîné"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1lrkbjxbXpq"
      },
      "source": [
        "Nous commencerons par télécharger le modèle. Les modèles ImageNet entraînés peuvent être téléchargés directement dans la bibliothèque Keras. Vous pouvez consulter les modèles disponibles et leurs détails [ici] (https://keras.io/api/applications/#available-models). N'importe lequel de ces modèles peut être utilisé pour notre exercice. \n",
        "\n",
        "Nous choisirons un modèle couramment utilisé appelé [VGG16](https://keras.io/api/applications/vgg/) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DielKjoKbXpr"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "  \n",
        "# load the VGG16 network *pre-trained* on the ImageNet dataset\n",
        "model = VGG16(weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYGkdCbEbXpt"
      },
      "source": [
        "Maintenant qu'il est chargé, jetons un coup d'œil au modèle. Il ressemble beaucoup à notre modèle convolutif de l'exercice sur le langage des signes. Faites attention à la première couche (la couche d'entrée) et à la dernière couche (la couche de sortie). Comme pour les exercices précédents, nous devons nous assurer que nos images correspondent aux dimensions d'entrée attendues par le modèle. Il est également utile de comprendre ce que le modèle renverra de la couche de sortie finale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC2novIWbXpu"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJNQrs7kbXpu"
      },
      "source": [
        "### Dimensions d'entrée\n",
        "Nous pouvons voir que le modèle attend des images de la forme (224, 224, 3) correspondant à 224 pixels de haut, 224 pixels de large et 3 canaux de couleur. Comme nous l'avons appris dans notre dernier exercice, les modèles Keras peuvent accepter plus d'une image à la fois pour la prédiction. Si nous ne transmettons qu'une seule image, la forme sera (1, 224, 224, 3). Nous devrons nous assurer que les images que nous transmettons à notre modèle pour la prédiction correspondent à ces dimensions. \n",
        "\n",
        "### Dimensions de sortie\n",
        "Nous pouvons également constater que le modèle renvoie une prédiction de la forme 1000. Rappelez-vous que dans notre premier exercice (MNIST), la forme de sortie de notre modèle était 10, correspondant aux 10 chiffres différents. \n",
        "Ici, nous avons 1000 catégories possibles dans lesquelles l'image sera placée. Bien que l'ensemble des données ImageNet comporte plus de 20 000 catégories, le concours et les modèles pré-entraînés qui en résultent n'utilisent qu'un sous-ensemble de 1000 de ces catégories. Nous pouvons jeter un coup d'œil à toutes ces [catégories possibles] (https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). \n",
        "\n",
        "Un grand nombre de ces catégories sont des animaux, y compris de nombreux types de chiens et de chats. Les chiens sont les catégories 151 à 268. Les chats sont les catégories 281 à 285. Nous pourrons utiliser ces catégories pour indiquer à notre porte pour chien quel type d'animal se trouve à notre porte et si nous devons le laisser entrer ou non.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_pfl1fpbXpv"
      },
      "source": [
        "## Chargement d'une image\n",
        "Nous allons commencer par charger une image et l'afficher, comme nous l'avons fait dans les exercices précédents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaKpPhG3fBdc"
      },
      "source": [
        "!wget http://urca.lsteffenel.fr/IntroDL/data.tar.gz -O data.tar.gz\n",
        "!tar -xvzf data.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQewAJJ7bXpv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def show_image(image_path):\n",
        "    image = mpimg.imread(image_path)\n",
        "    print(image.shape)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-oYRmNmbXpw"
      },
      "source": [
        "show_image(\"data/doggy_door_images/happy_dog.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6nAxyC7bXpw"
      },
      "source": [
        "## Preprocessement de l'image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8aXSipmbXpw"
      },
      "source": [
        "Ensuite, nous devons prétraiter l'image pour qu'elle soit prête à être envoyée dans le modèle. C'est exactement ce que nous avons fait dans notre dernier exercice lorsque nous avons prédit les images de la langue des signes. Rappelez-vous que dans ce cas, la forme finale de l'image doit être (1, 224, 224, 3).\n",
        "\n",
        "Lorsque nous chargeons des modèles directement avec Keras, nous pouvons également profiter des méthodes [`preprocess_input`] (https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/preprocess_input). Ces méthodes, associées à un modèle spécifique, permettent aux utilisateurs de prétraiter leurs propres images pour qu'elles correspondent aux qualités des images sur lesquelles le modèle a été entraîné à l'origine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HB79Ai8bXpx"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "def load_and_process_image(image_path):\n",
        "    # Print image's original shape, for reference\n",
        "    print('Original image shape: ', mpimg.imread(image_path).shape)\n",
        "    \n",
        "    # Load in the image with a target size of 224, 224\n",
        "    image = image_utils.load_img(image_path, target_size=(224, 224))\n",
        "    # Convert the image from a PIL format to a numpy array\n",
        "    image = image_utils.img_to_array(image)\n",
        "    # Add a dimension for number of images, in our case 1\n",
        "    image = image.reshape(1,224,224,3)\n",
        "    # Preprocess image to align with original ImageNet dataset\n",
        "    image = preprocess_input(image)\n",
        "    # Print image's shape after processing\n",
        "    print('Processed image shape: ', image.shape)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xHJ-eHFlbXpx"
      },
      "source": [
        "processed_image = load_and_process_image(\"data/doggy_door_images/brown_bear.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjlxY69bXpx"
      },
      "source": [
        "## Exercice : Faire une Prédiction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMH7ZqQ7bXpy"
      },
      "source": [
        "Maintenant que notre image est au bon format, nous pouvons la passer dans notre modèle et obtenir une prédiction. Nous nous attendons à obtenir un tableau de 1000 éléments, ce qui sera difficile à lire. Heureusement, les modèles chargés directement avec Keras disposent d'une autre méthode utile qui traduira ce tableau de prédiction sous une forme plus lisible. \n",
        "\n",
        "Remplissez la fonction suivante (dans les cases **FIXME**) pour implémenter la prédiction :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9AoA4sybXpy"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "\n",
        "def readable_prediction(image_path):\n",
        "    # Show image\n",
        "    FIXME\n",
        "    # Load and pre-process image\n",
        "    image = FIXME\n",
        "    # Make predictions\n",
        "    predictions = FIXME\n",
        "    # Print predictions in readable form\n",
        "    print('Predicted:', decode_predictions(predictions, top=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "\n",
        "def readable_prediction(image_path):\n",
        "    # Show image\n",
        "    show_image(image_path)\n",
        "    # Load and pre-process image\n",
        "    image = load_and_process_image(image_path)\n",
        "    # Make predictions\n",
        "    predictions = model.predict(image)\n",
        "    # Print predictions in readable form\n",
        "    print('Predicted:', decode_predictions(predictions, top=3))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PZarIt1lzOLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xalMS3fxbXpz"
      },
      "source": [
        "Essayez-le sur quelques animaux pour voir les résultats ! N'hésitez pas non plus à télécharger vos propres images et à les classer par catégorie pour voir comment cela fonctionne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLjHBu6DbXpz"
      },
      "source": [
        "readable_prediction(\"data/doggy_door_images/happy_dog.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-wofztfbXpz"
      },
      "source": [
        "readable_prediction(\"data/doggy_door_images/brown_bear.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQR4yaxbXpz"
      },
      "source": [
        "readable_prediction(\"data/doggy_door_images/sleepy_cat.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvFXQThpbXp0"
      },
      "source": [
        "## Exercice 2 : Seulement des Chiens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QRJplPLbXp0"
      },
      "source": [
        "Maintenant que nous faisons des prédictions avec notre modèle, nous pouvons utiliser nos catégories pour ne laisser entrer et sortir que les chiens et garder les chats à l'intérieur. Rappelez-vous que les chiens correspondent aux catégories 151 à 268 et les chats aux catégories 281 à 285. La fonction [np.argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) permet de déterminer quel élément du tableau de prédiction est la catégorie supérieure.\n",
        "\n",
        "Remplissez les cases **FIXME**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z_zk1DfbXp0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def doggy_door(image_path):\n",
        "    show_image(image_path)\n",
        "    image = load_and_process_image(image_path)\n",
        "    preds = model.predict(image)\n",
        "    if FIXME:\n",
        "        print(\"Doggy come on in!\")\n",
        "    elif FIXME:\n",
        "        print(\"Kitty stay inside!\")\n",
        "    else:\n",
        "        print(\"You're not a dog! Stay outside!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def doggy_door(image_path):\n",
        "    show_image(image_path)\n",
        "    image = load_and_process_image(image_path)\n",
        "    preds = model.predict(image)\n",
        "    if 151 <= np.argmax(preds) <= 268:\n",
        "        print(\"Doggy come on in!\")\n",
        "    elif 281 <= np.argmax(preds) <= 285:\n",
        "        print(\"Kitty stay inside!\")\n",
        "    else:\n",
        "        print(\"You're not a dog! Stay outside!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UO0oBwJuz1kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "VpQFwZL2Xx5l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0ipG2ngbXp1"
      },
      "source": [
        "doggy_door(\"data/doggy_door_images/brown_bear.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFugqS3ybXp1"
      },
      "source": [
        "doggy_door(\"data/doggy_door_images/happy_dog.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NajuTsClbXp1"
      },
      "source": [
        "doggy_door(\"data/doggy_door_images/sleepy_cat.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS6LvE5bbXp1"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COdA2Z58bXp1"
      },
      "source": [
        "Un travail remarquable ! En utilisant un puissant modèle pré-entraîné, nous avons créé une porte pour chien fonctionnelle en seulement quelques lignes de code. Nous espérons que vous êtes heureux de réaliser que vous pouvez tirer parti de l'apprentissage profond sans beaucoup de travail initial. Le plus intéressant est qu'au fur et à mesure que la communauté de l'apprentissage profond progresse, d'autres modèles seront disponibles pour que vous puissiez les utiliser dans vos propres projets."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNsSs2kj0GZk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}