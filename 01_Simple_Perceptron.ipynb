{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lsteffenel/ED-SNI-IntroDL/blob/main/01_Simple_Perceptron.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "lu5BrpZHOZIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Perceptron Model 1957\n",
        "Dans cet exemple nous allons utiliser la bibliothèque sklearn pour implémenter un Perceptron (modèle 1957) et travailler sur les données du dataset IRIS (qui datent de 1936) !\n",
        "\n",
        "\n",
        "## Objectifs :\n",
        " - Implémenter un classifieur linéaire historique avec un dataset historique !\n",
        " - L'objectif est de prédire la variété d'Iris à partir de la taille de ses pétales/sépales.\n",
        " - Identifier les limitations d'un seul neurone  \n",
        "\n",
        "Le [dataset IRIS](https://archive.ics.uci.edu/ml/datasets/Iris) est probablement l'un des plus anciens datasets, datant de 1936.\n",
        "\n",
        "## Ce qu'on fera :\n",
        " - Récupérérer le dataset via la bibliothèque scikit-learn\n",
        " - l'entraîner et faire une classification\n",
        "\n",
        "## Etape 1 - Importation des bibliothèques et initialisation"
      ],
      "metadata": {
        "id": "7rivVHssbvuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets     import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import os,sys\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NMZ1f-iFbvuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etape 2 - Préparer le dataset IRIS\n",
        "\n",
        "La plupart des bibliothèques de machine learning ont des datasets \"exemple\" directement accessibles\n",
        "Dans le cas de Scikit-Learn, ces datasets se trouvent dans le module suivant :\n",
        "Comment récupérer un dataset : http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets  \n",
        "La liste des datesets : http://scikit-learn.org/stable/datasets/index.html  \n",
        "\n",
        "Les différents attributs (X) :\n",
        "- 0 : sepal length in cm\n",
        "- 1 : sepal width in cm\n",
        "- 2 : petal length in cm\n",
        "- 3 : petal width in cm  \n",
        "\n",
        "Les classes (y) :\n",
        "- 0 : class 0=Iris-Setosa, 1=Iris-Versicolour, 2=Iris-Virginica\n",
        "\n",
        "### 2.1 - Charger le dataset"
      ],
      "metadata": {
        "id": "0tObFVVibvuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0,y0 = load_iris(return_X_y=True)\n",
        "\n",
        "x = x0[:, (2,3)]     # nous allons garder juste les features 2 et 3 (données des pétales)\n",
        "y = y0.copy()\n",
        "\n",
        "y[ y0==0 ] = 1       # 1 = Iris setosa\n",
        "y[ y0>=1 ] = 0       # 0 = not iris setosa\n",
        "\n",
        "df=pd.DataFrame.from_dict({'Length (x1)':x[:,0], 'Width (x2)':x[:,1], 'Setosa {0,1} (y)':y})\n",
        "display(df)\n",
        "\n",
        "print(f'x shape : {x.shape}')\n",
        "print(f'y shape : {y.shape}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "V0HtsHA1bvuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 - Créer les datasets d'entraînement (Train) et de Test"
      ],
      "metadata": {
        "id": "AIQg4QF_bvuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_np_dataset(x, y): # fonction pour mélanger aléatoirement le dataset\n",
        "    \"\"\"\n",
        "    Shuffle a dataset (x,y)\n",
        "    args:\n",
        "        x,y : dataset\n",
        "    return:\n",
        "        x,y mixed\n",
        "    \"\"\"\n",
        "    assert (len(x) == len(y)), \"x and y must have same size\"\n",
        "    p = np.random.permutation(len(x))\n",
        "    return x[p], y[p]\n",
        "\n",
        "x,y = shuffle_np_dataset(x, y)\n",
        "    \n",
        "n=int(len(x)*0.8)\n",
        "x_train = x[:n]\n",
        "y_train = y[:n]\n",
        "x_test  = x[n:]\n",
        "y_test  = y[n:]\n",
        "\n",
        "print(f'x_train shape : {x_train.shape}')\n",
        "print(f'y_train shape : {y_train.shape}')\n",
        "print(f'x_test shape  : {x_test.shape}')\n",
        "print(f'y_test shape  : {y_test.shape}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "0f1unez6bvua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Créer un perceptron et l'entraîner"
      ],
      "metadata": {
        "id": "TbM0sPIbbvua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pct = Perceptron(max_iter=100, random_state=82, tol=0.01, verbose=1)\n",
        "# nous avons limité l'entraînement à un max de 100 itérations\n",
        "# l'option \"tol\" permet d'arrêter l'entraînement plus tôt, si le gain est inférieur à 0.01\n",
        "\n",
        "pct.fit(x_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PZaCDMrabvua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etape 4 - Prédictions\n",
        "\n",
        "Le perceptron a été entraîné uniquement sur les données Train. On peut maintenant faire des estimations avec les données Test.\n",
        "Les colonnes `y_test`et `y_pred` correspondent respectivement aux labels du dataset et aux labels prédicts."
      ],
      "metadata": {
        "id": "SGJH4EbEbvub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pct.predict(x_test) \n",
        "\n",
        "df=pd.DataFrame.from_dict({'Length (x1)':x_test[:,0], 'Width (x2)':x_test[:,1], 'y_test':y_test, 'y_pred':y_pred})\n",
        "display(df[:15])"
      ],
      "metadata": {
        "trusted": true,
        "id": "601CXHmVbvub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Visualisation\n",
        "\n",
        "Le paragraphe suivant fait la visualisation des données précédentes. Il affiche les données Train (en couleurs foncées) et les données Test. Les couleurs correspondent aux labels, et la ligne pointillée montre la séparation faite par le perceptron."
      ],
      "metadata": {
        "id": "hk5MxVhxbvub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_perceptron(x_train,y_train,x_test,y_test):\n",
        "    a = -pct.coef_[0][0] / pct.coef_[0][1]\n",
        "    b = -pct.intercept_ / pct.coef_[0][1]\n",
        "    box=[x.min(axis=0)[0],x.max(axis=0)[0],x.min(axis=0)[1],x.max(axis=0)[1]]\n",
        "    mx=(box[1]-box[0])/20\n",
        "    my=(box[3]-box[2])/20\n",
        "    box=[box[0]-mx,box[1]+mx,box[2]-my,box[3]+my]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "    fig.set_size_inches(10,6)\n",
        " \n",
        "    axs.plot(x_train[y_train==1, 0], x_train[y_train==1, 1], \"o\", color='tomato', label=\"Iris-Setosa\")\n",
        "    axs.plot(x_train[y_train==0, 0], x_train[y_train==0, 1], \"o\", color='steelblue',label=\"Autres\")\n",
        "    \n",
        "    axs.plot(x_test[y_pred==1, 0],   x_test[y_pred==1, 1],   \"o\", color='lightsalmon', label=\"Iris-Setosa (pred)\")\n",
        "    axs.plot(x_test[y_pred==0, 0],   x_test[y_pred==0, 1],   \"o\", color='lightblue',   label=\"Autres (pred)\")\n",
        "    \n",
        "    axs.plot([box[0], box[1]], [a*box[0]+b, a*box[1]+b], \"k--\", linewidth=2)\n",
        "    axs.set_xlabel(\"Petal length (cm)\", labelpad=15) #, fontsize=14)\n",
        "    axs.set_ylabel(\"Petal width (cm)\",  labelpad=15) #, fontsize=14)\n",
        "    axs.legend(loc=\"lower right\", fontsize=14)\n",
        "    axs.set_xlim(box[0],box[1])\n",
        "    axs.set_ylim(box[2],box[3])\n",
        "    plt.show()\n",
        "    \n",
        "plot_perceptron(x_train,y_train, x_test,y_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HzpK052obvub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k42SgiErbvuc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}